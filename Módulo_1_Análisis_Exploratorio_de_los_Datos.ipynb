{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxBNpc7azmGF0mro6LpABZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justorfc/Estadistica_Aplicada/blob/main/M%C3%B3dulo_1_An%C3%A1lisis_Exploratorio_de_los_Datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Módulo_1 Análisis Exploratorio de los Datos**\n",
        "\n",
        "Bienvenidos al módulo \"Análisis Exploratorio de los Datos\" de tu curso de Estadística con Python y R. Exploraremos las fundamentales técnicas y conceptos necesarios para comprender y analizar conjuntos de datos de manera efectiva.\n",
        "\n",
        "El análisis exploratorio de datos (EDA) es la base sobre la cual se construyen todas las etapas del proceso de análisis de datos. Nos permite obtener una visión preliminar y comprensión profunda de nuestros datos antes de emprender cualquier análisis más avanzado. A lo largo de este módulo, desglosaremos los principios clave del EDA y exploraremos cómo aplicarlos utilizando Python y sus bibliotecas especializadas.\n",
        "\n",
        "Desde las bases de la probabilidad frecuentista hasta la visualización de distribuciones de probabilidad y la utilización de herramientas como scipy.stats y el módulo fitter para ajustar distribuciones, este módulo está diseñado para equiparte con las habilidades necesarias para manejar datos de manera rigurosa y efectiva.\n",
        "\n",
        "Ya seas un principiante emocionado por sumergirse en el mundo del análisis de datos o un profesional experimentado que busca refrescar tus conocimientos, este módulo te proporcionará el conocimiento esencial para llevar a cabo un análisis exploratorio sólido y valioso."
      ],
      "metadata": {
        "id": "6yDg0TRSjeiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Palabras Claves del Módulo Análisis Exploratorio de los Datos**\n",
        "\n",
        "El siguiente es un listado de palabras clave que serán utilizadas en el presente notebook:\n",
        "\n",
        "## Palabras Clave\n",
        "\n",
        "- Análisis Exploratorio de Datos (EDA)\n",
        "- Probabilidad Frecuentista\n",
        "- Variables Aleatorias Discretas y Continuas\n",
        "- Distribuciones de Probabilidad\n",
        "- Visualización de Datos\n",
        "- Histograma\n",
        "- Gráfico de Densidad\n",
        "- Gráfico de Probabilidad Normal\n",
        "- Ajuste de Distribuciones\n",
        "- `scipy.stats`\n",
        "- Módulo `fitter`\n",
        "- Media, Mediana y Moda\n",
        "- Desviación Estándar\n",
        "- Cuartiles y Percentiles\n",
        "- Diagrama de Dispersión\n",
        "- Correlación\n",
        "- Diagrama de Caja (Box Plot)\n",
        "- Valores Atípicos\n",
        "- Normalización y Estandarización\n",
        "- Matriz de Correlación\n",
        "- Matplotlib\n",
        "- Seaborn\n",
        "- Jupyter Notebook\n"
      ],
      "metadata": {
        "id": "UJi3Kuo8rmBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Objetivos y Competencias**\n",
        "\n",
        "**Objetivo General:**\n",
        "El objetivo principal de este módulo es proporcionar a los participantes las habilidades esenciales para llevar a cabo un análisis exploratorio de datos sólido y efectivo utilizando herramientas y técnicas de programación en Python. Al finalizar este módulo, los participantes estarán equipados para comprender, visualizar y explorar conjuntos de datos de manera rigurosa, identificando patrones, tendencias y peculiaridades que guiarán análisis más profundos y decisiones informadas.\n",
        "\n",
        "**Competencias Desarrolladas:**\n",
        "\n",
        "1. **Comprensión de EDA:** Los participantes desarrollarán una comprensión sólida de los conceptos fundamentales del Análisis Exploratorio de Datos (EDA), incluyendo la importancia de la comprensión inicial de los datos antes de realizar análisis más avanzados.\n",
        "\n",
        "2. **Manipulación de Datos:** Aprenderán a limpiar y preparar datos para su análisis, incluyendo la detección y manejo de valores atípicos, datos faltantes y errores.\n",
        "\n",
        "3. **Visualización de Datos:** Desarrollarán habilidades en la creación de visualizaciones efectivas para representar distribuciones de datos, patrones de correlación, y otras relaciones relevantes.\n",
        "\n",
        "4. **Uso de Bibliotecas:** Utilizarán bibliotecas como Matplotlib y Seaborn para crear gráficos informativos y presentaciones visuales de datos.\n",
        "\n",
        "5. **Interpretación de Resultados:** Aprenderán a interpretar los resultados de las visualizaciones y a identificar patrones, tendencias y relaciones importantes presentes en los datos.\n",
        "\n",
        "6. **Estadísticas Descriptivas:** Adquirirán conocimientos sobre medidas descriptivas como la media, mediana, moda, desviación estándar, cuartiles y percentiles.\n",
        "\n",
        "7. **Distribuciones de Probabilidad:** Comprenderán diferentes tipos de distribuciones de probabilidad y cómo ajustar estas distribuciones a los datos reales.\n",
        "\n",
        "8. **Utilización de `scipy.stats` y `fitter`:** Aprenderán a utilizar la biblioteca `scipy.stats` y el módulo `fitter` para ajustar distribuciones de probabilidad a los datos y evaluar su idoneidad.\n",
        "\n",
        "9. **Análisis de Correlación:** Desarrollarán habilidades para analizar la correlación entre variables y utilizarán herramientas para identificar relaciones lineales y no lineales.\n",
        "\n",
        "10. **Exploración Avanzada:** Se familiarizarán con técnicas avanzadas como normalización, estandarización y creación de matrices de correlación.\n",
        "\n",
        "Al abordar estos temas y desarrollar estas competencias, los participantes estarán preparados para aplicar el Análisis Exploratorio de Datos en diversas situaciones y serán capaces de tomar decisiones informadas basadas en la comprensión profunda de los datos."
      ],
      "metadata": {
        "id": "g4cr9TGLstC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plan para Desarrollar el “Módulo_1 Análisis Exploratorio de los Datos”**\n",
        "\n",
        "Por supuesto, aquí tienes el plan reescrito con breves indicaciones para el estudiante sobre cómo realizar las acciones en el documento de RMarkdown en RStudio Cloud, además de los enlaces relevantes:\n",
        "\n",
        "**Plan para Desarrollar el \"Módulo_1 Análisis Exploratorio de los Datos\" en RStudio Cloud**\n",
        "\n",
        "1. **Crear el Documento de RMarkdown:**\n",
        "   - En RStudio Cloud, crea un nuevo documento de RMarkdown llamado \"Módulo_1 Análisis Exploratorio de los Datos\".\n",
        "   - Utiliza encabezados y formato Markdown para estructurar tu documento y explicar cada sección.\n",
        "\n",
        "2. **Transferir Contenidos del Notebook de Python:**\n",
        "   - Abre el notebook \"ANALISIS DE UNA VARIABLE.ipynb\" en Google Colab desde la URL proporcionada.\n",
        "   - Copia y pega los contenidos relevantes en las celdas de código y texto en tu documento RMarkdown.\n",
        "   - Asegúrate de ajustar la sintaxis y la lógica para que funcione en el entorno de R.\n",
        "\n",
        "3. **Instalar el Paquete \"reticulate\":**\n",
        "   - En una celda de código de tu documento RMarkdown, instala el paquete \"reticulate\" en R mediante la siguiente línea:\n",
        "     ```\n",
        "     install.packages(\"reticulate\")\n",
        "     ```\n",
        "\n",
        "4. **Instalar Paquetes de Python en RStudio:**\n",
        "   - Utiliza una celda de código para instalar los paquetes de Python necesarios. Por ejemplo, para instalar \"seaborn\", escribe:\n",
        "     ```\n",
        "     reticulate::py_install(\"seaborn\")\n",
        "     ```\n",
        "   - Repite este paso para cada paquete mencionado en tu plan.\n",
        "\n",
        "5. **Uso de Módulos de Python para EDA:**\n",
        "   - En tu documento RMarkdown, introduce el uso de módulos de Python para EDA.\n",
        "   - Utiliza la biblioteca \"dataprep\" para realizar exploración de datos. Puedes encontrar información y ejemplos en [este enlace](https://dataprep.ai/).\n",
        "   - Explora otros módulos como \"AutoEDA\", \"pandas-profiling\", \"Sweetviz\" y \"Autoviz\". Encuentra más detalles y ejemplos en [este artículo](https://www.analyticsvidhya.com/blog/2021/08/better-eda-with-3-easy-python-libraries-for-any-beginner/).\n",
        "\n",
        "6. **Crear Visualizaciones y Análisis:**\n",
        "   - Combina tus explicaciones con celdas de código en Python utilizando la notación de \"reticulate\". Esto te permitirá ejecutar código de Python en el mismo documento de RMarkdown.\n",
        "   - Utiliza las bibliotecas de visualización de Python para crear gráficos y análisis exploratorio.\n",
        "\n",
        "Siguiendo este plan, podrás integrar de manera efectiva el análisis exploratorio de datos realizado en Python en tu documento de RMarkdown en RStudio Cloud. Si tienes dudas o enfrentas problemas en algún punto, no dudes en preguntar a ChatGPT."
      ],
      "metadata": {
        "id": "8oUQscpktpAl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gTIgmVvFtZKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sP26pmznxKDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrPWq8g5nX30"
      },
      "source": [
        "# **1. EDA: Análisis Exploratorio de Datos Unidimensional**\n",
        "\n",
        "**[EDA: Análisis exploratorio de datos](https://es.wikipedia.org/wiki/An%C3%A1lisis_exploratorio_de_datos)**\n",
        "\n",
        "Las visualizaciones son una herramienta fundamental para entender y compartir ideas sobre los datos. La visualización correcta puede ayudar a expresar una idea central, o abrir un espacio para una más profunda investigación; con ella se puede conseguir que todo el mundo hable sobre un conjunto de datos, o compartir una visión sobre lo que los datos nos quieren decir. [Visualizaciones de datos con Python](https://relopezbriega.github.io/blog/2016/09/18/visualizaciones-de-datos-con-python/)\n",
        "\n",
        "La organización de la información:\n",
        "* [HISTOGRAMAS](https://es.wikipedia.org/wiki/Histograma)\n",
        "* [POLIGONOS DE FRECUENCIAS](https://definicion.de/poligono-de-frecuencia/#:~:text=Pol%C3%ADgono%20de%20frecuencia%20es%20el,mayor%20altura%20de%20estas%20columnas.)\n",
        "* [OJIVAS](https://es.wikipedia.org/wiki/Ojiva_(estad%C3%ADstica)#:~:text=En%20estad%C3%ADstica%2C%20una%20ojiva%20es,y%20la%20frecuencia%20acumulativa%20correspondiente.)\n",
        "\n",
        "Sea X una variable aleatoria de la cual se toma una muestra que consiste de n datos:\n",
        "x1, x2, … xn. Que no han sido ordenados. En la creación de una tabla de distribución de frecuencias, se denominan datos agrupados a los datos dispuestos de manera tabular mediante clases o categorías, dentro de cada una de las cuales caen un número determinado de datos (frecuencia de clase), el siguiente es el procedimiento:\n",
        "\n",
        "1.\tCalcular el número de intervalos, k. Se recomienda que $k<=5*ln(n)$ (en R: $k<=5*log(n)$), hay varios métodos para calcular k, de los siguientes se recomienda tomar la parte entera de:\n",
        "    *\t10*log10(n)\tDixon y Kronmal (1965)\n",
        "    *\t2*n^1/2\t\tVelleman (1976)\n",
        "    *\t1+log2(n)\t\tSturges (1926)\n",
        "    *\t1+3.322*log(n)\tSturges (1926)\n",
        "2.\tCalcular el rango, r = max(x)-min(x)\n",
        "3.\tCalcular el tamaño o extensión de cada intervalo w ≈ r/k\n",
        "    *\tDe tal manera que w*k >=r\n",
        "4.\tHistograma. Marcas de clase, f, h, F, H\n",
        "5.\tPolígono de frecuencia\n",
        "6.\tOjiva\n",
        "\n",
        "\n",
        "|k|linf|lsup|mc|f|h|F|H|\n",
        "|-|----|----|--|-|-|-|-|\n",
        "|1|linf[1]|lsup[1]|mc[1]|f[1]|h[1]|F[1]|H[1]|\n",
        "|2|linf[2]|lsup[2]|mc[2]|f[2]|h[2]|F[2]|H[2]|\n",
        "|…|…|…|…|…|…|…|…|\n",
        "|n|linf[n]|lsup[n]|mc[n]|f[n]|h[n]|F[n]|H[n]|\n",
        "\n",
        "Donde:\n",
        "+ k:\tEl número del intervalo\n",
        "+ linf:\tEl límite Inferior del intervalo k\n",
        "+ lsup:\tEl límite superior del intervalo k\n",
        "+ mc:\tMarca de clase: mc = (linf+lsup)/2\n",
        "+ f;\tFrecuencia Absoluta. Numero de datos que caen entre los límites del intervalo k\n",
        "+ h:\tFrecuencia Relativa. h = f/n\n",
        "+ F:\tFrecuencias Absolutas acumuladas. F[i+1]=F[i]+h[i+1]\n",
        "+ H;\tFrecuencia Relativas acumuladas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gueZD3kFl2P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "symngmeqpsjW"
      },
      "source": [
        "# **2. PROBABILIDAD FRECUENTISTA**\n",
        "\n",
        "***La probabilidad es el lenguaje matemático para cuantificar la incertidumbre***\n",
        "\n",
        "FRECUENCIA RELATIVA O  “A POSTERIORI”: Este concepto es conocido como el “Enfoque Frecuentista” o “Método Empírico”.\n",
        "\n",
        "La proximidad de la frecuencia relativa a la probabilidad depende de la repetibilidad de algún proceso y de la posibilidad de contar el número de repeticiones, así como el número de veces que algún evento de interés ocurre.\n",
        "\n",
        "DEFINICION: Si después de N repeticiones de un experimento, es decir, si N es el número total de veces que se realiza el experimento, donde N es muy grande, y NE es el número total de veces que ocurre un evento E, la frecuencia relativa de la ocurrencia de E es NE/N, y la probabilidad P de obtener un evento E es.\n",
        "\n",
        "$$\n",
        "P(E) = \\lim_{N->\\infty}\\frac{N_E}{N}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NOTA:** Novedad de versiones de RPy2\n",
        "\n",
        "[Conversion 'py2rpy' not defined for objects of type '<class 'str'>'](https://stackoverflow.com/questions/74283327/conversion-py2rpy-not-defined-for-objects-of-type-class-str)\n",
        "\n",
        "```\n",
        "!pip uninstall rpy2 -y\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "# !pip install rpy2==3.0.0\n",
        "!pip install rpy2==3.5.1\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "# R Magic\n",
        "%load_ext rpy2.ipython\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "# Esto tiene formato de código\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_sPqO2YT71GI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzqOmkGDaYWf"
      },
      "source": [
        "# En caso de que desee usar Python y R juntos, puede usar R magic para algunas celdas.\n",
        "\n",
        "**NOTA:** Novedad de versiones de RPy2\n",
        "\n",
        "[Conversion 'py2rpy' not defined for objects of type '<class 'str'>'](https://stackoverflow.com/questions/74283327/conversion-py2rpy-not-defined-for-objects-of-type-class-str)\n",
        "\n",
        "**Puede que necesite desinstalar rpy2, use, en una celda de código de Python:**\n",
        "\n",
        "```\n",
        "!pip uninstall rpy2 -y\n",
        "```\n",
        "\n",
        "**Luego instale rpy2 versión 3 ó 3.5.1**\n",
        "\n",
        "```\n",
        "# !pip install rpy2==3.0.0\n",
        "!pip install rpy2==3.5.1\n",
        "```\n",
        "\n",
        "Luego puede activar R magic con:\n",
        "\n",
        "```\n",
        "%load_ext rpy2.ipython\n",
        "```\n",
        "\n",
        "Luego, siempre que desee usar R, comience la celda con %%R\n",
        "\n",
        "```\n",
        "%%R\n",
        "x <- 42\n",
        "print(x)\n",
        "```\n",
        "\n",
        "```\n",
        "%%R\n",
        "x <- 42\n",
        "x\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall rpy2 -y"
      ],
      "metadata": {
        "id": "3qux5_Dg7Gz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install rpy2==3.0.0\n",
        "!pip install rpy2==3.5.1"
      ],
      "metadata": {
        "id": "009h004_6Be4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjljSsZD7DG_"
      },
      "source": [
        "# R Magic\n",
        "%load_ext rpy2.ipython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrsgP1yy7Cuc"
      },
      "source": [
        "%%R\n",
        "x <- 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaqzS873wI93"
      },
      "source": [
        "%%R\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEMOSTRACIÓN EXPERIMENTAL DE LA PROBABILIDAD FRECUENTISTA\n",
        "\n",
        "**EXPERIMENTO 1**. Se desea simular un experimento consistente en un control automático de refrigeración de seis locales mediante la activación automática de seis unidades de aire acondicionado. Cada aire acondicionado se disparará cuando la temperatura suba a un nivel determinado. Demuestre que en el línite cuando N es muy grande la frecuencia relativa es la probabilidad.\n",
        "\n",
        "**SOLUCIÓN**. Tenemos seis aires acondicionados: A1, A2, A3, A4, A5 y A6. Cada aire acondicionado se disparará cuando el control automático lo determine, luego la frecuencia relativa de que se dispare uno de los seis aires acondicionados es 1/6 = 0.16666666666666666. En R podemos utilizar la función **sample()** para simular el experimento, luego obtendremos las frecuencias absolutas y la frecuencias relativas con las funciones **table()** y **prop.table()**, aumentaremos las veces que se repite el experimento (N, resultados posibles) y miraremos la frecuencia relativa como se acerca al valor de la probabilidad de 1/6 = 0.16666666666666666"
      ],
      "metadata": {
        "id": "rMp1c-D1BwLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos R Magic\n",
        "%load_ext rpy2.ipython"
      ],
      "metadata": {
        "id": "_87k1rdnFA8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF1cAZ2OwIRa"
      },
      "source": [
        "%%R\n",
        "help(sample)\n",
        "# Función sample()\n",
        "# Random Samples and Permutations\n",
        "# ‘sample’ takes a sample of the specified size from the elements of\n",
        "#     ‘x’ using either with or without replacement."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-DvQIssxaQk"
      },
      "source": [
        "%%R\n",
        "x = 1:12\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSZacACWxaCm"
      },
      "source": [
        "%%R\n",
        "sample(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "sample(x,size=15)\n",
        "# Produce un error"
      ],
      "metadata": {
        "id": "Orlvtd-NFNNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny6jdkJCx0EA"
      },
      "source": [
        "%%R\n",
        "sample(x,size=15, replace=T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yub6IIccxz0v"
      },
      "source": [
        "# Ejemplo de un experimento donde se debe seleccionar un resultado cualquiera de seis resultados posibles\n",
        "%%R\n",
        "x = 1:6\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eaw4Omk4ztrI"
      },
      "source": [
        "%%R\n",
        "1/6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueIJiiqizeyx"
      },
      "source": [
        "%%R\n",
        "table(sample(x, 10, replace=T))\n",
        "# La función table cuenta las frecuencias absolutas de una muestra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JagUaBGnzenS",
        "collapsed": true
      },
      "source": [
        "%%R\n",
        "prop.table(table(sample(x, 100, replace=T)))\n",
        "# La función prop.table() calcula las frecuencias relativas de una table()\n",
        "\n",
        "# ESTO DEMUESTRA EL CONCEPTO FRECUENTISTA DE LA PROBABILIDAD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGiaCs9UFlvf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfuiw1UK20KB"
      },
      "source": [
        "# Hagamoslo ahora con python\n",
        "\n",
        "Repasemos como crear una serie de pandas:\n",
        "\n",
        "[Crear una Serie de Pandas](https://es.acervolima.com/crear-una-serie-de-pandas/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "list = ['A1', 'A2', 'A3', 'A4', 'A5','A6']\n",
        "\n",
        "ser = pd.Series(list)\n",
        "print(ser)"
      ],
      "metadata": {
        "id": "af73nxzgF5ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1k6wMyGytRD"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "x = ['A1', 'A2', 'A3', 'A4', 'A5','A6']   # Una lista\n",
        "\n",
        "x = pd.Series(x)    # Debo convertirla en una Serie de Pandas\n",
        "\n",
        "m = x.sample(n=10,replace=True) # Extraigo 10 muestras CON REEMPLAZO\n",
        "                                # AUMENTO N A 100, 1000, 10000, ETC\n",
        "\n",
        "n = len(m)  # Obtengo el número total de resultados posibles\n",
        "\n",
        "print(m.value_counts()/n)   # Cuento las frecuencias relativas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb98FT_JrLaM"
      },
      "source": [
        "# **un histograma tiene como objetivo aproximar la función de densidad (pdf) de probabilidad subyacente que genero los datos agrupando y contando observaciones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4-M3Z2NCjcA"
      },
      "source": [
        "# **Histograma y Densidad**\n",
        "\n",
        "Una de las mejores maneras de describir una variable es informar los valores que aparecen en el conjunto de datos y cuántas veces aparece cada valor. Esta descripción se llama **la distribución de la variable**. La representación más común de una distribución es un histograma, que es un gráfico que muestra la frecuencia de cada valor. En este contexto, \"frecuencia\" significa el número de veces que aparece el valor.\n",
        "\n",
        "¿Densidad, cómo es eso? La densidad describe como la variable aleatoria tomará determinados valores.\n",
        "\n",
        "Cuando se dibuja un histograma se representarán con las barras las densidades.\n",
        "\n",
        "Con el comando hist(), de R, se puede indicar la densidad agregando el argumento freq:\n",
        "\n",
        "```\n",
        "hist(x, freq=F)\n",
        "```\n",
        "\n",
        "+ **freq = TRUE** indica la frecuencia absoluta (conteo) en el eje y (es el valor por defecto).\n",
        "+ **freq = FALSE** indica la densidad (Frecuencia Relativa o probabilidad). Se dice entonces que se traza un histograma de densidad. Si se quiere trazar la línea de densidad, se debe lanzar la siguiente orden:\n",
        "\n",
        "```\n",
        "lines(density(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-UE49Bf5i-M"
      },
      "source": [
        "# Tabla de Distribución de Frecuencias con R\n",
        "\n",
        "```\n",
        "tdf <- function(x) {\n",
        "  # Calcula la Tabla de Distribuci?n de Frecuencias por Intervalos\n",
        "  # Grafica el histograma y la curva de densidad\n",
        "  n=length(x)\n",
        "  k=1+3.322*log10(n)\n",
        "  k=floor(k)\n",
        "  r=max(x,na.rm = T)-min(x,na.rm = T)\n",
        "  w=r/k\n",
        "  w=ceiling(w)\n",
        "  linf=min(x,na.rm = T)\n",
        "  for (i in 1:k)\n",
        "  {\n",
        "    linf[i+1]=linf[i]+w\n",
        "  }\n",
        "  lsup=NA\n",
        "  for (i in 1:k)\n",
        "  {\n",
        "    if (is.integer(x))\n",
        "    {\n",
        "      lsup[i]=linf[i+1]-1\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "      lsup[i]=linf[i+1]-0.01\n",
        "    }\n",
        "  }\n",
        "  f=NA\n",
        "  for (i in 1:k)\n",
        "  {\n",
        "    f[i]=length(which(x>=linf[i] & x<=lsup[i]))\n",
        "  }\n",
        "  linf=linf[1:k]\n",
        "  mc=(lsup+linf)/2\n",
        "  tdf=data.frame(linf=linf,lsup=lsup,mc=mc,f=f)\n",
        "  h=f/sum(f)\n",
        "  tdf=data.frame(linf=linf,lsup=lsup,mc=mc,f=f,h=h)\n",
        "  F=NA\n",
        "  for (i in 1:k)\n",
        "  {\n",
        "    if (i==1)\n",
        "      F[i]=f[i]\n",
        "    else\n",
        "      F[i]=f[i]+F[i-1]\n",
        "  }\n",
        "  tdf=data.frame(tdf,F=F)\n",
        "  H=NA\n",
        "  for (i in 1:k)\n",
        "  {\n",
        "    if (i==1)\n",
        "      H[i]=h[i]\n",
        "    else\n",
        "      H[i]=h[i]+H[i-1]\n",
        "  }\n",
        "  tdf=data.frame(tdf,H=H)\n",
        "  print(tdf)\n",
        "\n",
        "  par(mfrow=c(2,2))\n",
        "  hist(x,freq = F)\n",
        "  density(x,na.rm = T)\n",
        "  hist(x, freq = F)\n",
        "  lines(density(x,na.rm = T))\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qARdIlRouKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PUEDE QUE NECESITE \"Desconectar y borrar el tiempo de ejecución\" y luego reconectar**"
      ],
      "metadata": {
        "id": "2bfNfb6LoPTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall rpy2 -y"
      ],
      "metadata": {
        "id": "Xo_glElVnRgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install rpy2==3.0.0\n",
        "!pip install rpy2==3.5.1"
      ],
      "metadata": {
        "id": "sqn1iDHPm3Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos R Magic\n",
        "%load_ext rpy2.ipython"
      ],
      "metadata": {
        "id": "DWZ_FkzEmt2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00US3VWkxZ0U"
      },
      "source": [
        "%%R\n",
        "tdf <- function(x) {\n",
        "  # Calcula la Tabla de Distribuci?n de Frecuencias por Intervalos\n",
        "  # Grafica el histograma y la curva de densidad\n",
        "  n=length(x)\n",
        "  k=1+3.322*log10(n)\n",
        "  k=floor(k)\n",
        "  r=max(x,na.rm = T)-min(x,na.rm = T)\n",
        "  w=r/k\n",
        "  w=ceiling(w)\n",
        "  linf=min(x,na.rm = T)\n",
        "  for (i in 1:k)\n",
        "  {\n",
        "    linf[i+1]=linf[i]+w\n",
        "  }\n",
        "  lsup=NA\n",
        "  for (i in 1:k)\n",
        "  {\n",
        "    if (is.integer(x))\n",
        "    {\n",
        "      lsup[i]=linf[i+1]-1\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "      lsup[i]=linf[i+1]-0.01\n",
        "    }\n",
        "  }\n",
        "  f=NA\n",
        "  for (i in 1:k)\n",
        "  {\n",
        "    f[i]=length(which(x>=linf[i] & x<=lsup[i]))\n",
        "  }\n",
        "  linf=linf[1:k]\n",
        "  mc=(lsup+linf)/2\n",
        "  tdf=data.frame(linf=linf,lsup=lsup,mc=mc,f=f)\n",
        "  h=f/sum(f)\n",
        "  tdf=data.frame(linf=linf,lsup=lsup,mc=mc,f=f,h=h)\n",
        "  F=NA\n",
        "  for (i in 1:k)\n",
        "  {\n",
        "    if (i==1)\n",
        "      F[i]=f[i]\n",
        "    else\n",
        "      F[i]=f[i]+F[i-1]\n",
        "  }\n",
        "  tdf=data.frame(tdf,F=F)\n",
        "  H=NA\n",
        "  for (i in 1:k)\n",
        "  {\n",
        "    if (i==1)\n",
        "      H[i]=h[i]\n",
        "    else\n",
        "      H[i]=h[i]+H[i-1]\n",
        "  }\n",
        "  tdf=data.frame(tdf,H=H)\n",
        "  print(tdf)\n",
        "\n",
        "#  par(mfrow=c(2,2))\n",
        "#  hist(x,freq = F)\n",
        "#  density(x,na.rm = T)\n",
        "#  hist(x, freq = F)\n",
        "#  lines(density(x,na.rm = T))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dfcfJ3tlGZZ"
      },
      "source": [
        "%%R\n",
        "library(MASS)\n",
        "data(Boston)\n",
        "names(Boston)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "medv = Boston$medv\n",
        "tdf(medv)"
      ],
      "metadata": {
        "id": "l-EvcsoafMaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "summary(medv)"
      ],
      "metadata": {
        "id": "yoOOdBJvgX1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEiSXmLFxoOF"
      },
      "source": [
        "# **3. Variables aleatorias discretas y continua**s.\n",
        "\n",
        "Para comprender de una manera más amplia y rigurosa los tipos de variables, es necesario conocer la definición de conjunto discreto. Un conjunto es discreto si está formado por un número finito de elementos, o si sus elementos se pueden enumerar en secuencia de modo que haya un primer elemento, un segundo elemento, un tercer elemento, y así sucesivamente.\n",
        "\n",
        "**Variable aleatoria discreta**: una v.a. es discreta si su recorrido es un conjunto discreto. La variable Hora del ejemplo anterior es discreta.\n",
        "\n",
        "**Variable aleatoria continua**: una v.a. es continua si su recorrido no es un conjunto numerable. Intuitivamente esto significa que el conjunto de posibles valores de la variable abarca todo un intervalo de números reales. Por ejemplo, la variable que asigna la Humedad Relativa (HR) a un flujo aire caliente entrando en el plenum de un secador de granos, es una variable continua ya que, teóricamente, todo valor entre, pongamos por caso, 10% y 20%, es posible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ut4CFcjKB7L"
      },
      "source": [
        "#### DEFINICIONES. Las siguientes son algunas definiciones de Variable Aleatoria, va:\n",
        "\n",
        "**DEFINICION 1 de Variable Aleatoria**: Una función X de valor real sobre el espacio muestral Ω, se llama “Variable Aleatoria” sobre el Espacio de Probabilidad (Ω, f, P) si para todo conjunto de Borel en Rn, el conjunto:\n",
        "$${X∈B}={w:X(w)∈B}$$\n",
        "Es un elemento de la familia de eventos f.\n",
        "\n",
        "Intuitivamente podemos hablar de una va X como una cantidad que en cada observación aleatoria w, asume un valor real X(w) determinado por esta observación, los eventos de la forma {X€B} donde B es un elemento de Rn, son eventos determinados por condiciones sobre X. (Moreno, Luis, p. 29).\n",
        "\n",
        "**FUNCIÓN DE PROBABILIDAD**. Una función de conjunto no negativa y aditiva P sobre la familia f, recibe el nombre de “medida de probabilidad” o “función de probabilidad”, si P es “normada”; esto es, si:\n",
        "\n",
        "$$PΩ=1$$\n",
        "\n",
        "La tripleta (Ω, f, P), formada por el espacio muestral Ω, la familia de subconjuntos de Ω, y la función de probabilidad P, se conoce con el nombre de “Espacio de Probabilidad”. La escogencia de (Ω, f, P) depende de la información conocida sobre los detalles del experimento y del problema que se va a plantear.\n",
        "\n",
        "f, es una familia de subconjuntos del espacio muestral Ω que cumple las siguientes condiciones:\n",
        "1. φ€f\n",
        "2. $A^c=Ω-A€f$, si A€f\n",
        "3. Si $A_n€f$, para n=1,2,…, entonces $U_{n=1}^\\infty A_n€f$\n",
        "\n",
        "**DEFINICION 2 de Variable Aleatoria**: Si Ω es un espacio muestral con una medida de probabilidad y X es una función con valor real definida en los elementos de Ω, entonces X se denomina Variable Aleatoria. (Wisniewski y Velasco, P. 113)\n",
        "\n",
        "Esto significa que **una va es propiamente una función** que asigna un número real a cada evento de un espacio muestral. Se acostumbra usar letras mayúsculas (Usualmente T, W, X, Y, Z), para denotar variables aleatorias. Por ejemplo, si queremos expresar la probabilidad de que cierta variable aleatoria X asuma algún valor no menor a 4, entonces se escribe así: P (2≤X≤4).\n",
        "\n",
        "**DEFINICION 3**: Una variable aleatoria (v.a.) es un número real asociado al resultado de un experimento aleatorio, es decir, una función real en el espacio muestral, X: Ω→ℜ\n",
        "\n",
        "Una variable aleatoria es una función, que asigna eventos a números reales. Una variable aleatoria o variable estocástica es una variable estadística cuyos valores se obtienen de mediciones en experimentos aleatorios.\n",
        "\n",
        "Los valores posibles de una variable aleatoria pueden representar los posibles resultados de un experimento aún no realizado, o los posibles valores de una cantidad cuyo valor actualmente existente es incierto (p.e., como resultado de medición incompleta o imprecisa). Intuitivamente, una variable aleatoria puede tomarse como una cantidad cuyo valor no es fijo pero puede tomar diferentes valores; una distribución de probabilidad se usa para describir la probabilidad de que se den los diferentes valores. (Wikipedia)\n",
        "\n",
        "Una variable aleatoria puede concebirse como un valor numérico que está afectado por el azar. Dada una variable aleatoria no es posible conocer con certeza el valor que tomará esta al ser medida o determinada, aunque sí se conoce que existe una distribución de probabilidad asociada al conjunto de valores posibles. Por ejemplo, en una epidemia de cólera, se sabe que una persona cualquiera puede enfermar o no (suceso), pero no se sabe cuál de los dos sucesos va a ocurrir. Solamente se puede decir que existe una probabilidad de que la persona enferme. (Wikipedia). Otro ejemplo en un experimento de secado a campo abierto se sabe que el secador puede desempeñarse eficientemente o no (suceso) pero no se sabe cuál de los dos sucesos ocurrirá eficiente o no. Solamente se se puede decir que existe una probabilidad de que el secador se desempeñe eficientemente.\n",
        "\n",
        "Para trabajar de manera sólida con variables aleatorias en general es necesario considerar un gran número de experimentos aleatorios, para su tratamiento estadístico, cuantificar los resultados de modo que se asigne un número real a cada uno de los resultados posibles del experimento. De este modo se establece una relación funcional entre elementos del espacio muestral asociado al experimento y números reales. (Wikipedia).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYpowjlYwie9"
      },
      "source": [
        "Ejemplo: A continuación se muestran los valores de precipitaciones por año en cm.\n",
        "\n",
        "\n",
        "|año|Y(cm)|\n",
        "|---|-----|\n",
        "|1911|101.35|\n",
        "|1912|78.74|\n",
        "|1913|107.44|\n",
        "|1914|106.93|\n",
        "|1915|104.39|\n",
        "|1916|72.90|\n",
        "|1917|42.67|\n",
        "\n",
        "A la función Y que asigna los cm de precipitación a cada año, se le llama variable aleatoria.\n",
        "\n",
        "\n",
        "|Hora|dT|Ec|Ea|Y (Es)|\n",
        "|----|--|--|--|------|\n",
        "|0|3.0|57.0|0.0|0.0|\n",
        "|1|2.0|45.5|-1.3|15.1|\n",
        "|2|4.1|53.7|15.4|30.7|\n",
        "|3|4.0|57.3|13.1|26.5|\n",
        "\n",
        "En la tabla anterior se aprecian valores de Gradientes de temperatura (dT), Eficiencias de Colección en un secador solar (Ec), Eficiencias de absorción de un lecho de piedras (Ea) y eficiencias del sistema secador solar (Es), todas ellas en función de la hora del día (Hora). Estos son ejemplos de variables aleatorias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AZ-zFttx1wX"
      },
      "source": [
        "# **4. DISTRIBUCIONES DE PROBABILIDAD**.\n",
        "\n",
        "Las distribuciones de probabilidad son un concepto fundamental en estadística. Las distribuciones de probabilidad se utilizan tanto a nivel teorico como a nivel práctico.\n",
        "\n",
        "Necesidad: En muchas ocasiones tenemos interés en la probabilidad de que una variable cualquiera tome un valor particular.\n",
        "\n",
        "**DEFINICIÓN**: La distribución de probabilidad de una Variable Aleatoria X es una descripción de las probailidades asociadas con los valores posibles de X. Esta distribución de probabilidad puede expresarse como un listado o tabla, o como una fórmula. (Padilla A. John).\n",
        "\n",
        "EJEMPLO: La siguiente tabla muestra losprimeros datos de un experimento con Maiz de diferentes procedencias.\n",
        "\n",
        "\n",
        "|Raza|Altura|Diametro|Hojas|Endospermo|Grano|Mazorca|\n",
        "|----|------|--------|-----|----------|-----|-------|\n",
        "|CUBANYELLO|120|15|12|6|2|1|\n",
        "|CUBANYELLO|169|11|12|2|1|3|\n",
        "|TUZON|184|17|13|6|2|2|\n",
        "|TUZON|283|19|15|4|3|2|\n",
        "\n",
        "La siguiente podría ser la tabla de distribución de frecuencias del número de hojas por planta:\n",
        "\n",
        "|Hojas|Frecuencia|\n",
        "|-----|----------|\n",
        "|12|8|\n",
        "|13|22|\n",
        "|14|29|\n",
        "|15|13|\n",
        "|16|1|\n",
        "|Total general|73|\n",
        "\n",
        "Se pretende construir la distribución de probabilidad de la variable aleatoria discreta Hojas, donde Hojas es el número de Hojas por planta. La siguiente tabla representa las distribuciones de probablidad.\n",
        "\n",
        "|Hojas|Frecuencia|P(X=x)|\n",
        "|-----|----------|------|\n",
        "|12|8|10.96%|\n",
        "|13|22|30.14%|\n",
        "|14|29|39.73%|\n",
        "|15|13|17.81%|\n",
        "|16|1|1.37%|\n",
        "|Total general|73|100%|\n",
        "\n",
        "En la tabla anterior los valores de X son: x1=12, x2=13. Se calculan las probabilidades para estos valores que no son mas que las frecuencias relativas bajo el concepto frecuentista de la probabilidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O-YgpWBzxuY"
      },
      "source": [
        "#### Ejemplo: Experimento del mercurio\n",
        "\n",
        "En la tabla siguiente se muestran las frecuencias absolutas y relativas del Hg en el experimento del profesor Luis Dias:\n",
        "\n",
        "|Li|Ls|Hg|f|h|F|H|\n",
        "|--|--|--|-|-|-|-|\n",
        "|0|5|2.5|70|0.8750|70|0.875|\n",
        "|5|10|7.5|4|0.0500|74|0.925|\n",
        "|10|15|12.5|1|0.0125|75|0.9375|\n",
        "|15|20|17.5|4|0.0500|79|0.9875|\n",
        "|20|25|22.5|0|0.0000|79|0.9875|\n",
        "|25|30|27.5|1|0.0125|80|1|\n",
        "\n",
        "Bajo el concepto frecuentista de la probabilidad podemos presentar los intervalos de los valores de Hg con sus respectivas frecuencias relativas de la siguiente forma:\n",
        "\n",
        "|Hg||P(Hg)|\n",
        "|--|-----|-|\n",
        "|Li|Ls||\n",
        "|0|5|0.875|\n",
        "|5|10|0.050|\n",
        "|10|15|0.013|\n",
        "|15|20|0.050|\n",
        "|20|25|0.000|\n",
        "|25|30|0.013|\n",
        "\n",
        "Donde Hg son todos los resultados posibles y P(Hg) es la probabilidad de que en el experimento se obtenga el valor correspondiente de Hg (suceso) en el intervalo dado. Observe que la sumatoria de P(Hg) es igual a 1, lo cual es conforme a los axiomas de la probabilidad.\n",
        "\n",
        "---\n",
        "\n",
        "**El conjunto de pares ordenados (Hg, f(Hg)) es una función de probabilidades**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kg0HSPJ11nn"
      },
      "source": [
        "En el ejemplo del número de Hojas por planta en el experimento de Maiz, La variable aleatoria Hojas es una variable aleatoria discreta y a la función de probabilidades P(X=x) se le denomina función de masa de probabilidad.\n",
        "\n",
        "En el ejemplo del mercurio, Hg, es una variable aleatoria continua y la función de probabilidades P(Hg) se le denomina función de densidad de probabilidad y suele representarse por f(x) (Letra minúscula).\n",
        "\n",
        "Cada variable aleatoria, sea discreta o continua, tiene asociada una distribución de probabilidad (aunque esta pudiera ser desconocida), la cual se expresa en general por medio de una fórmula o de alguna tabla.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od-rYZFx149D"
      },
      "source": [
        "#### La Distribución de Probabilidad\n",
        "\n",
        "La Distribución de Probabilidad es una especie de ley matemática que rige el comportamiento estocástico (o aleatorio) de la variable aleatoria en cuestión (Wisniewski y Velasco).\n",
        "\n",
        "En muchos fenómenos naturales (Físicos, químicos o biológicos) y económicos, las distribuciones de probabilidad de las variables aleatorias que intervienen están bien identificadas y estudiadas; en otros fenómenos, semejantes distribuciones son desconocidas y suelen manejarse de manera empírica o aproximada; todavía hay otros fenómenos en los cuales ni siquiera es es posible y suelen enfocarse por medio de otros métodos estaísticos conocidos como No Paramétricos. (Wisniewski y Velasco).\n",
        "\n",
        "Es pertinente señalar que las propiedades y fórmulas para las variables aleatorias discretas y continuas son diferentes, pero se parecen mucho. A menudo, la única diferencia estriba en el cambio de una suma (Σ) por una integral (∫).\n",
        "\n",
        "Con frecuencia nos interesa conocer la probabilidad de que el valor de una variable aleatoria sea menor que o igual a un número real x. De hecho, casi todas las tablas estadísticas así funcionan. Esto se escribe como: F(x) = P(X≤x) y se denomina a esta función definida para todos los números reales x como la Función de Distribución Acumulada (fda), o simplemente distribución acumulada para la variable aleatoria X. (Wisniewski y Velasco). El siguiente cuadro resume las propiedades anteriores:\n",
        "\n",
        "\n",
        "|Caso Discreto|Caso Continuo|\n",
        "|-------------|-------------|\n",
        "|P(X=x)=p(x)=f(x)|f(x) = Expresión matemática de la f.d.p.|\n",
        "|0≤f(x)≤1|0≤f(x)≤1|\n",
        "|$\\sum_{toda x}f(x)=\\sum_{i=1}^n(p_i)=1$|$\\int_{-∞}^{∞}f(x)dx=1$|\n",
        "|F(x)=P(X≤x)=txf(t)|Fx=PX≤x=-∞ftdt|\n",
        "|P(a≤X≤b)=F(b)-F(a)|P(a<X<b)=P(a≤X≤b)=F(b)-F(a)|\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwOb1bb6lQKo"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5HT8ynklQlW"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Histogramas + Densidad](https://picandoconr.wordpress.com/2016/02/21/histogramas-densidad/)\n",
        "\n",
        "Densidad. Cuando algo es más denso es porque existe en una concentración mayor que una referencia."
      ],
      "metadata": {
        "id": "LH9ebInpu1NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activamos R Magic\n",
        "%load_ext rpy2.ipython\n",
        "# Luego siempre se desee usar R dentro de Python, comenzar la celda con %%R"
      ],
      "metadata": {
        "id": "TN_eH5KfvaJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "z <- c(3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1,\n",
        "       3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8,\n",
        "       3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2,\n",
        "       3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.6, 3.0, 3.4,\n",
        "       3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3)"
      ],
      "metadata": {
        "id": "E37ms3UhvWK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Ahora dibujemos un histograma\n",
        "hist(z)"
      ],
      "metadata": {
        "id": "mkGDTPomv9hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que los valores que más abundan en nuestro conjunto de datos son los que están entre 3 y 4.\n",
        "\n",
        "Bueno, con esto podemos decir que la densidad es mayor entre esos valores.\n",
        "\n",
        "Siguiendo la misma lógica podemos decir que la densidad es menor para los valores entre 2 y 2.5 y entre 4 y 4.5. Simple, ¿cierto?\n",
        "\n",
        "Podemos indicar la densidad en el histograma con un argumento del comando hist. Si revisas la ayuda (?hist) podrás encontrar el argumento freq que puede tomar valores TRUE o FALSE (verdadero o falso), así:\n",
        "\n",
        "+ freq = TRUE indica la frecuencia absoluta (conteo) en el eje y (es el valor por defecto).\n",
        "+ freq = FALSE indica la densidad."
      ],
      "metadata": {
        "id": "Y8PgCuHlwI9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "hist(z, freq = FALSE)"
      ],
      "metadata": {
        "id": "1YPlMqKSwpEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa que lo único que cambia es el nombre en el eje y (ahora se indica la densidad con la palabra Density).\n",
        "\n",
        "Los histogramas pueden ser confusos cuando vemos el mismo conjunto de datos con diferentes intervalos de clase (categorías). Por ejemplo, podemos cambiar el método para calcular los intervalos de clase «Sturges» (valor por defecto) por el valor «Freedman-Diaconis» (FD)."
      ],
      "metadata": {
        "id": "DyPq2_brwsFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "hist(z, freq = FALSE, breaks = \"FD\")"
      ],
      "metadata": {
        "id": "x91Hg_T4w3jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque el histograma cambia se puede seguir observando que la mayoría de valores está entre 3 y 4 ¿verdad?\n",
        "\n",
        "Bueno pues, hay una forma de dibujar la densidad y evitar la confusión con los intervalos de clase.\n",
        "\n",
        "Si queremos conocer la densidad usamos el comando density sobre nuestro conjunto de datos, así:"
      ],
      "metadata": {
        "id": "5zPDCXYbw9xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "density(z)"
      ],
      "metadata": {
        "id": "xxFTPqzIwrET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos dibujar estos valores simplemente aplicamos el comando plot a todo eso, así:"
      ],
      "metadata": {
        "id": "nKQRmQyPxD_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "plot(density(z))"
      ],
      "metadata": {
        "id": "EITCeInDwCiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esa curva es la curva de densidad de nuestro conjunto de datos.\n",
        "\n",
        "Esta curva es una función matemática y tiene una fórmula que la describe. La curva es el resultado de la unión de puntos [x, y] que se muestran como resumen (valores de x y valores de y) cuando aplicas density(z).\n",
        "\n",
        "Resulta que esta curva no depende de los intervalos por lo que siempre será la misma.\n",
        "\n",
        "Podemos compararla con un histograma de densidad (freq = FALSE como argumento).\n",
        "\n",
        "Primero dibujaremos el histograma (con argumento freq = FALSE) y luego dibujaremos la densidad sobre ese gráfico, sin embargo, presta atención al reemplazo del comando plot por lines cuando grafiquemos la curva de densidad."
      ],
      "metadata": {
        "id": "i0TKdS5qxM-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "hist(z, freq = F)\n",
        "lines(density(z))"
      ],
      "metadata": {
        "id": "kfV-kEqpxmbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿qué pasa si cambio el número de intervalos de clase?\n",
        "\n",
        "Veamos:\n",
        "\n",
        "Ya que vamos a comparar dos métodos («Sturges» y «Freedman-Diaconis») dibujaré los mismos ejes en ambos gráficos (xlim y ylim iguales en cada gráfico)."
      ],
      "metadata": {
        "id": "_3tC-G1ZxwOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "hist(z, freq = F, xlim = c(2, 5), ylim =c(0, 1.1),\n",
        "     breaks = \"Sturges\")\n",
        "\n",
        "lines(density(z))"
      ],
      "metadata": {
        "id": "uG3a2SGDxxsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método «Freedman-Diaconis»"
      ],
      "metadata": {
        "id": "jYOSz0u-x8pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "hist(z, freq = F, xlim = c(2, 5), ylim =c(0, 1.1),\n",
        "     breaks = \"FD\")\n",
        "\n",
        "lines(density(z))"
      ],
      "metadata": {
        "id": "uDpdf-Tlx9f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como puedes ver, el histograma cambia pero no lo hace la curva de densidad :)\n",
        "\n",
        "Incluso podemos crear más intervalos de clase y la curva no cambiará."
      ],
      "metadata": {
        "id": "DLDnra28yJjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "hist(z, freq = F, xlim = c(2, 5), ylim =c(0, 1.1),\n",
        "     breaks = 20)\n",
        "\n",
        "lines(density(z))"
      ],
      "metadata": {
        "id": "YTQ5iWN3yFBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXScI-0QhSJ4"
      },
      "source": [
        "# **5. [VISUALIZAR LA DISTRIBUCION DE UN CONJUNTO DE DATOS CON PYTHON](https://seaborn.pydata.org/tutorial/distributions.html)**\n",
        "\n",
        "Cuando se trata de un conjunto de datos, a menudo lo primero que querrá hacer es tener una idea de cómo se distribuye la variable. Este capítulo del tutorial dará una breve introducción a algunas de las herramientas en seaborn para examinar distribuciones univariadas y bivariadas. También puede consultar el capítulo de [diagramas categóricos](https://seaborn.pydata.org/tutorial/categorical.html#categorical-tutorial) para ver ejemplos de funciones que facilitan la comparación de la distribución de una variable entre niveles de otras variables. (**Un buen ejercicio es crear un cuaderno con el tutorial del link anterior**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HElyUu2itIT"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZv8Wg7ajHS8"
      },
      "source": [
        "sns.set(color_codes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re7Z4fR-jXUP"
      },
      "source": [
        "#### **Trazar distribuciones univariadas**\n",
        "\n",
        "La forma más conveniente de echar un vistazo rápido a una distribución univariada en seaborn es la función [distplot()](https://seaborn.pydata.org/generated/seaborn.distplot.html#seaborn.distplot).\n",
        "\n",
        "Por defecto, esto dibujará un [histograma](https://es.wikipedia.org/wiki/Histograma) y se ajustará a una estimación de densidad del núcleo ([KDE: kernel density estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiM91YuQjQ3P"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "x = np.random.normal(size=1000)\n",
        "\n",
        "sns.distplot(x)\n",
        "# plot a univariate distribution of observations."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5qp5xhjhRNi"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "x = np.random.binomial(3,0.5,10000)\n",
        "\n",
        "sns.distplot(x);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czlr4COnMirC"
      },
      "source": [
        "x = np.random.normal(size=100)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9oeKtHLMica"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNiDp_V3kwo-"
      },
      "source": [
        "#### Histogramas\n",
        "\n",
        "Es probable que los histogramas sean familiares, y ya existe una función [hist()](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist.html) en matplotlib. Un histograma representa la distribución de datos formando contenedores a lo largo del rango de los datos y luego dibujando barras para mostrar el número de observaciones que caen en cada contenedor.\n",
        "\n",
        "Para ilustrar esto, eliminemos la curva de densidad y agreguemos un diagrama de alfombra, que dibuja una pequeña marca vertical en cada observación. Puede hacer que la alfombra se trace con la función [rugplot()](https://seaborn.pydata.org/generated/seaborn.rugplot.html#seaborn.rugplot), pero también está disponible en [distplot()](https://seaborn.pydata.org/generated/seaborn.distplot.html#seaborn.distplot):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_RnEZnCztlH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.random.normal(size=100)\n",
        "\n",
        "plt.hist(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1wHa2__jQuY"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "x = np.random.normal(size=100)\n",
        "\n",
        "sns.distplot(x, kde=False, rug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bhk6CVKq9lb"
      },
      "source": [
        "Al dibujar histogramas, la opción principal que tiene es la cantidad de contenedores que debe usar y dónde colocarlos. La función [distplot()](https://seaborn.pydata.org/generated/seaborn.distplot.html#seaborn.distplot) usa una regla simple para adivinar cuál es el número correcto de forma predeterminada, pero probar más o menos contenedores puede revelar otras características en los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22BGMRdNjQmk"
      },
      "source": [
        "sns.distplot(x, bins=10, kde=True, rug=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1GzxHhYbSZq"
      },
      "source": [
        "# Modifiquemos el número de bins\n",
        "sns.distplot(x, bins=6, kde=True, rug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdqmsVu5bSEr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbIkrt8BrX6n"
      },
      "source": [
        "#### Estimación de la densidad del núcleo\n",
        "\n",
        "La estimación de la densidad del núcleo puede ser menos familiar, pero puede ser una herramienta útil para trazar la forma de una distribución. Al igual que el histograma, los gráficos de [KDE: kernel density estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation) codifican la densidad de observaciones en un eje con altura a lo largo del otro eje:\n",
        "\n",
        "[Estimación de la densidad de kernel](https://hmong.es/wiki/Kernel_density_estimation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gmro0NyjQe2"
      },
      "source": [
        "sns.distplot(x, hist=False, rug=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzxpxP_Rr6sg"
      },
      "source": [
        "Dibujar un KDE está más involucrado computacionalmente que dibujar un histograma. Lo que sucede es que cada observación se reemplaza primero con una [curva normal](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal).  centrada en ese valor. Curva también llamada: [gaussiana](https://es.wikipedia.org/wiki/Funci%C3%B3n_gaussiana):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xhmkLs3jQVr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats   # Contiene muchas distribuciones de probabilidad\n",
        "\n",
        "x = np.random.normal(0, 1, size=30)\n",
        "\n",
        "bandwidth = 1.06 * x.std() * x.size ** (-1 / 5.)\n",
        "\n",
        "support = np.linspace(-4, 4, 200)\n",
        "\n",
        "kernels = []\n",
        "\n",
        "for x_i in x:\n",
        "\n",
        "    kernel = stats.norm(x_i, bandwidth).pdf(support)\n",
        "    kernels.append(kernel)\n",
        "    plt.plot(support, kernel, color=\"r\")\n",
        "\n",
        "sns.rugplot(x, color=\".2\", linewidth=3);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4kl6Q77QCI9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59HRrxN6vMM7"
      },
      "source": [
        "A continuación, estas curvas se suman para calcular el valor de la densidad en cada punto de la cuadrícula de soporte. La curva resultante se normaliza para que el área debajo de ella sea igual a 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9u_00t1vU_5"
      },
      "source": [
        "from scipy.integrate import trapz\n",
        "\n",
        "density = np.sum(kernels, axis=0)\n",
        "density /= trapz(density, support)\n",
        "plt.plot(support, density);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBTzENPKvfnW"
      },
      "source": [
        "Podemos ver que si usamos la función [kdeplot()](https://seaborn.pydata.org/generated/seaborn.kdeplot.html#seaborn.kdeplot) en seaborn, obtenemos la misma curva. Esta función es utilizada por [distplot()](https://seaborn.pydata.org/generated/seaborn.distplot.html#seaborn.distplot), pero proporciona una interfaz más directa con un acceso más fácil a otras opciones cuando solo desea la estimación de densidad:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgTYwXDbvUnq"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.kdeplot(x);\n",
        "\n",
        "\"\"\"\n",
        "Plot univariate or bivariate distributions using kernel density estimation.\n",
        "\n",
        "A kernel density estimate (KDE) plot is a method for visualizing the\n",
        "distribution of observations in a dataset, analagous to a histogram. KDE\n",
        "represents the data using a continuous probability density curve in one or\n",
        "more dimensions.\n",
        "\n",
        "The approach is explained further in the user guide <tutorial_kde>.\n",
        "\n",
        "Relative to a histogram, KDE can produce a plot that is less cluttered and\n",
        "more interpretable, especially when drawing multiple distributions. But it\n",
        "has the potential to introduce distortions if the underlying distribution is\n",
        "bounded or not smooth. Like a histogram, the quality of the representation\n",
        "also depends on the selection of good smoothing parameters.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwn8melVv5VY"
      },
      "source": [
        "El **parámetro bandwidth (bw)** del KDE controla qué tan ajustada se ajusta la estimación a los datos, de forma muy similar al tamaño del bin en un histograma. Corresponde al ancho de los núcleos que trazamos arriba. El comportamiento predeterminado intenta adivinar un buen valor utilizando una regla de referencia común, pero puede ser útil probar valores más grandes o más pequeños:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UENTnypKwg54"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.kdeplot(x)\n",
        "sns.kdeplot(x, bw=.2, label=\"bw: 0.2\")\n",
        "sns.kdeplot(x, bw=2, label=\"bw: 2\")\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwHnmSXIwzQj"
      },
      "source": [
        "Como puede ver arriba, la naturaleza del proceso Gaussian KDE significa que la estimación se extiende más allá de los valores más grandes y más pequeños en el conjunto de datos. Es posible controlar cuánto más allá de los valores extremos se dibuja la curva con el parámetro **cut**; sin embargo, esto solo influye en cómo se dibuja la curva y no en cómo se ajusta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMB9YPA0xBSe"
      },
      "source": [
        "sns.kdeplot(x, shade=True, cut=0)\n",
        "sns.rugplot(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTRaOpV1mCI8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBk5SX9GxLyV"
      },
      "source": [
        "# **6. AJUSTANDO DISTRIBUCIONES DE PROBABILIDAD**\n",
        "\n",
        "El objetivo de la presente sección es ajustar una muestra de un conjunto de datos empíricos a un modelo de distribución teórico. El problema de ajustar distribuciones, puede ser dividido en tres grandes tareas:\n",
        "\n",
        "1. **Seleccionar un modelo teórico**. Este primer paso es bastante informal. En este primer paso pueden ser de mucho interés la estadística descriptiva de los datos, asi como histogramas, indicadores de asimetría y curtosis entre otros.\n",
        "2. **Estimar los parámetros del modelo**. Cada modelo teórico tiene sus propios parámetros, por ejemplo, para la distribución normal, son la media y la desviación estándar. Esta tarea consiste en estimar los parámetros del modelo más probable para el conjunto de datos empíricos.\n",
        "3. **Determinar la significancia del modelo, o la bondad del ajuste**. Este es el paso de mayor complicación, aquí se establece lo bien que los datos observados coinciden con el modelo teórico con los parámetros estimados. Si el nivel de significación computarizada es más allá de un umbral predefinido, la hipótesis de bondad de ajuste se acepta, de lo contrario se rechaza\n",
        "\n",
        "---\n",
        "\n",
        "También puede usar [distplot()](https://seaborn.pydata.org/generated/seaborn.distplot.html#seaborn.distplot) para ajustar una distribución paramétrica a un conjunto de datos y evaluar visualmente qué tan cerca corresponde a los datos observados:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id_1M7BFjPx3"
      },
      "source": [
        "# Realicemos un ajuste de unos datos ficticios UTILIZANDO EL PARÁMETRO FIT DE displot()\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "x = np.random.gamma(6, size=200)\n",
        "\n",
        "# UTILIZO displot() Y CON EL PARAMETRO fit, le paso la pdf teoríca a que quiero ajustar mis datos\n",
        "sns.distplot(x, kde=False, fit=stats.gamma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tQeN6tARNZS"
      },
      "source": [
        "dir(stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eLKSXYLQt3Y"
      },
      "source": [
        "# Realicemos un ajuste de unos datos ficticios UTILIZANDO EL PARÁMETRO FIT DE displot()\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "x = np.random.normal(size=100)\n",
        "\n",
        "# UTILIZO displot() Y CON EL PARAMETRO fit, le paso la pdf teoríca a que quiero ajustar mis datos\n",
        "sns.distplot(x, kde=False, fit=stats.norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KSWipQfI_U4"
      },
      "source": [
        "#### MODULO STATS DE SCIPY: [Statistics (scipy.stats)](https://docs.scipy.org/doc/scipy/tutorial/stats.html)\n",
        "\n",
        "**Introducción**\n",
        "\n",
        "Este módulo contiene una gran cantidad de distribuciones de probabilidad, así como una biblioteca cada vez mayor de funciones estadísticas. En esta sección, discutimos las características de **scipy.stats** La intención aquí es proporcionar al usuario un conocimiento práctico de este paquete.\n",
        "\n",
        "Nos referimos al [manual de Referencia](https://docs.scipy.org/doc/scipy/reference/stats.html#statsrefmanual) para obtener más detalles.\n",
        "\n",
        "1. [Distribuciones estadísticas discretas](https://docs.scipy.org/doc/scipy/reference/stats.html#discrete-distributions)\n",
        "2. [Distribuciones estadísticas continuas](https://docs.scipy.org/doc/scipy/reference/stats.html#continuous-distributions)\n",
        "3. [Estadística en Python con SciPy (I)](https://pybonacci.org/2012/04/21/estadistica-en-python-con-scipy/)\n",
        "4. [DISTRIBUCIONES DE PROBABILIDAD CON PYTHON](https://medium.com/@24nars/distribuciones-de-probabilidad-con-python-70b952395c65)\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "**ALGUNAS LECTURAS OMPLEMENTARIAS SOBRE SCIPY**\n",
        "\n",
        "1. [Scipy: computación científica de alto nivel](https://claudiovz.github.io/scipy-lecture-notes-ES/intro/scipy.html)\n",
        "2. [La librería científica Scipy](https://docs.scipy.org/doc/scipy/index.html)\n",
        "3. [Estadística en Python con SciPy (I)](https://pybonacci.org/2012/04/21/estadistica-en-python-con-scipy/)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btMnJb3llj_r"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yg5MRnM48Z-"
      },
      "source": [
        "# **GRAFICAR ALGUNAS DISTRIBUCIONES DE PROBABILIDAD**\n",
        "\n",
        "[Distribuciones estadísticas continuas en: **scipy.stats**](https://docs.scipy.org/doc/scipy/reference/stats.html#continuous-distributions)\n",
        "\n",
        "**Descripción general**. Todas las distribuciones tendrán parámetros de ubicación (L) y Escala (S) junto con los parámetros de forma necesarios, los nombres de los parámetros de forma variarán.\n",
        "\n",
        "+ [Alpha Distribution](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.alpha.html#scipy.stats.alpha). **Implementación: [scipy.stats.alpha](https://github.com/scipy/scipy/blob/v1.9.3/scipy/stats/_continuous_distns.py#L435-L486)**\n",
        "+ [Anglit Distribution](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anglit.html#scipy.stats.anglit). Implementation: [scipy.stats.anglit](https://github.com/scipy/scipy/blob/v1.9.3/scipy/stats/_continuous_distns.py#L492-L529shttps://github.com/scipy/scipy/blob/v1.9.3/scipy/stats/_continuous_distns.py#L492-L529)\n",
        "+ [Arcsine Distribution](https://docs.scipy.org/doc/scipy/reference/tutorial/stats/continuous_arcsine.html)\n",
        "+ Beta Distribution\n",
        "+ Beta Prime Distribution\n",
        "+ Bradford Distribution\n",
        "+ Burr Distribution\n",
        "+ Burr12 Distribution\n",
        "+ Cauchy Distribution\n",
        "+ Chi Distribution\n",
        "+ Chi-squared Distribution\n",
        "+ Cosine Distribution\n",
        "+ Double Gamma Distribution\n",
        "+ Double Weibull Distribution\n",
        "+ Erlang Distribution\n",
        "+ Exponential Distribution\n",
        "+ Exponentiated Weibull Distribution\n",
        "+ Exponential Power Distribution\n",
        "+ Fatigue Life (Birnbaum-Saunders) Distribution\n",
        "+ Fisk (Log Logistic) Distribution\n",
        "+ Folded Cauchy Distribution\n",
        "+ Folded Normal Distribution\n",
        "+ Fratio (or F) Distribution\n",
        "+ Gamma Distribution\n",
        "+ Generalized Logistic Distribution\n",
        "+ Generalized Pareto Distribution\n",
        "+ Generalized Exponential Distribution\n",
        "+ Generalized Extreme Value Distribution\n",
        "+ Generalized Gamma Distribution\n",
        "+ Generalized Half-Logistic Distribution\n",
        "+ Generalized Inverse Gaussian Distribution\n",
        "+ Generalized Normal Distribution\n",
        "+ Gilbrat Distribution\n",
        "+ Gompertz (Truncated Gumbel) Distribution\n",
        "+ Gumbel (LogWeibull, Fisher-Tippetts, Type I Extreme Value) Distribution\n",
        "+ Gumbel Left-skewed (for minimum order statistic) Distribution\n",
        "+ HalfCauchy Distribution\n",
        "+ HalfNormal Distribution\n",
        "+ Half-Logistic Distribution\n",
        "+ Hyperbolic Secant Distribution\n",
        "+ Gauss Hypergeometric Distribution\n",
        "+ Inverted Gamma Distribution\n",
        "+ Inverse Normal (Inverse Gaussian) Distribution\n",
        "+ Inverted Weibull Distribution\n",
        "+ Johnson SB Distribution\n",
        "+ Johnson SU Distribution\n",
        "+ KSone Distribution\n",
        "+ KStwo Distribution\n",
        "+ KStwobign Distribution\n",
        "+ Laplace (Double Exponential, Bilateral Exponential) Distribution\n",
        "+ Asymmetric Laplace Distribution\n",
        "+ Left-skewed Lévy Distribution\n",
        "+ Lévy Distribution\n",
        "+ Logistic (Sech-squared) Distribution\n",
        "+ Log Double Exponential (Log-Laplace) Distribution\n",
        "+ Log Gamma Distribution\n",
        "+ Log Normal (Cobb-Douglass) Distribution\n",
        "+ Log-Uniform Distribution\n",
        "+ Maxwell Distribution\n",
        "+ Mielke’s Beta-Kappa Distribution\n",
        "+ Nakagami Distribution\n",
        "+ Noncentral chi-squared Distribution\n",
        "+ Noncentral F Distribution\n",
        "+ Noncentral t Distribution\n",
        "+ Normal Distribution\n",
        "+ Normal Inverse Gaussian Distribution\n",
        "+ Pareto Distribution\n",
        "+ Pareto Second Kind (Lomax) Distribution\n",
        "+ Power Log Normal Distribution\n",
        "+ Power Normal Distribution\n",
        "+ Power-function Distribution\n",
        "+ R-distribution Distribution\n",
        "+ Rayleigh Distribution\n",
        "+ Rice Distribution\n",
        "+ Reciprocal Inverse Gaussian Distribution\n",
        "+ Semicircular Distribution\n",
        "+ Student t Distribution\n",
        "+ Trapezoidal Distribution\n",
        "+ Triangular Distribution\n",
        "+ Truncated Exponential Distribution\n",
        "+ Truncated Normal Distribution\n",
        "+ Tukey-Lambda Distribution\n",
        "+ Uniform Distribution\n",
        "+ Von Mises Distribution\n",
        "+ Wald Distribution\n",
        "+ Weibull Maximum Extreme Value Distribution\n",
        "+ Weibull Minimum Extreme Value Distribution\n",
        "+ Wrapped Cauchy Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMp7rgtO5eWH"
      },
      "source": [
        "#### **EJEMPLO: GRAFICAR LA DISTRIBUCIÓN NORMAL**\n",
        "\n",
        "[Normal Distribution](https://docs.scipy.org/doc/scipy/tutorial/stats/continuous_norm.html)\n",
        "\n",
        "$$\n",
        "f(x) = \\frac{e^{\\frac{-x^2}{2}}}{\\sqrt{2\\pi}}\n",
        "$$\n",
        "\n",
        "**[Implementación: ](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm)**\n",
        "\n",
        "**scipy.stats.norm**\n",
        "\n",
        "scipy.stats.norm(*args, **kwds) = <scipy.stats._continuous_distns.norm_gen object>\n",
        "\n",
        "Una variable aleatoria continua normal.\n",
        "\n",
        "La palabra clave **loc**  location() especifica la media. La palabra clave **scale** scale() especifica la desviación estándar.\n",
        "\n",
        "**Notas**\n",
        "\n",
        "La función de densidad de probabilidad para **norm** es:\n",
        "\n",
        "$$\n",
        "f(x) = \\frac{e^{\\frac{-x^2}{2}}}{\\sqrt{2\\pi}}\n",
        "$$\n",
        "\n",
        "para un número real $x$.\n",
        "\n",
        "Ejemplos:\n",
        "\n",
        "```\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "```\n",
        "\n",
        "Calcule algunos primeros momentos:\n",
        "\n",
        "```\n",
        "mean, var, skew, kurt = norm.stats(moments='mvsk')\n",
        "```\n",
        "\n",
        "Muestra la función de densidad de probabilidad ( pdf):\n",
        "\n",
        "```\n",
        "x = np.linspace(norm.ppf(0.01),\n",
        "                norm.ppf(0.99), 100)\n",
        "ax.plot(x, norm.pdf(x),\n",
        "       'r-', lw=5, alpha=0.6, label='norm pdf')\n",
        "```\n",
        "\n",
        "Alternativamente, se puede llamar al objeto de distribución (como una función) para fijar los parámetros de forma, ubicación y escala. Esto devuelve un objeto RV \"congelado\" que mantiene fijos los parámetros dados.\n",
        "\n",
        "Congelar la distribución y mostrar el congelado pdf:\n",
        "\n",
        "```\n",
        "rv = norm()\n",
        "ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
        "```\n",
        "\n",
        "Verifique la precisión de cdfy ppf:\n",
        "\n",
        "```\n",
        "vals = norm.ppf([0.001, 0.5, 0.999])\n",
        "np.allclose([0.001, 0.5, 0.999], norm.cdf(vals))\n",
        "```\n",
        "\n",
        "Genera números aleatorios:\n",
        "\n",
        "```\n",
        "r = norm.rvs(size=1000)\n",
        "```\n",
        "\n",
        "Y compare el histograma:\n",
        "\n",
        "```\n",
        "ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
        "ax.legend(loc='best', frameon=False)\n",
        "plt.show()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdsoiSEoIBX"
      },
      "source": [
        "**[ajustar datos a una distribución](https://blog.adrianistan.eu/estadistica-python-ajustar-datos-una-distribucion-parte-vii)**\n",
        "\n",
        "17/01/2018 - Adrián Arroyo Calle\n",
        "\n",
        "Existen modelos que nos hacen la vida más sencilla. ¿Qué pasa si tenemos datos y queremos ver si podemos estar ante un modelo de los ya definidos?\n",
        "\n",
        "Este tipo de ajuste es muy interesante, ya que nos permite saber si los datos en bruto pueden parecerse a los modelos de Normal u otros y aprovecharlo.\n",
        "\n",
        "**Ajuste de datos a una distribución**\n",
        "\n",
        "Para ajustar datos a una distribución, todas las distribuciones continuas de **SciPy** cuentan con la función **fit**. Fit nos devuelve los parámetros con los que ajusta nuestros datos al modelo. ¡Ojo, no nos avisa si es un buen ajuste o no!\n",
        "\n",
        "Ejemplo: Queremos saber si la altura de los hombres adultos del pueblo de Garray sigue una distribución normal. Para ello tomamos una muestra de 80 alturas de hombres adultos en Garray."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt-In35Dpk-l"
      },
      "source": [
        "altura = [180.55743416791302,\n",
        "159.4830930711535,\n",
        "175.54566032406794,\n",
        "149.06378740901533,\n",
        "140.35494067172635,\n",
        "146.65963134242543,\n",
        "171.34024710764376,\n",
        "140.11601629465872,\n",
        "175.6026441151595,\n",
        "158.00860559393507,\n",
        "122.53612034588375,\n",
        "116.10055909040616,\n",
        "152.89225061770068,\n",
        "148.31372767763455,\n",
        "111.17487190927599,\n",
        "160.18952563680827,\n",
        "151.8729737480722,\n",
        "141.50350042949614,\n",
        "165.2379297612276,\n",
        "150.75979657877465,\n",
        "171.5257501059296,\n",
        "157.97922034080895,\n",
        "159.60144363114716,\n",
        "152.52036681430164,\n",
        "172.0678524550487,\n",
        "163.65457704485283,\n",
        "134.9562174388093,\n",
        "189.70206097599245,\n",
        "153.78203142905076,\n",
        "176.1787894042539,\n",
        "190.83025195589502,\n",
        "199.04182673196726,\n",
        "146.97803776211907,\n",
        "174.22118528139467,\n",
        "170.95045320552694,\n",
        "161.2797407784266,\n",
        "190.61061242859464,\n",
        "168.79257731811308,\n",
        "159.87099716863165,\n",
        "136.22823975268153,\n",
        "166.87622973701335,\n",
        "179.58044852016417,\n",
        "172.49583957582817,\n",
        "165.2662334997042,\n",
        "136.6663345224381,\n",
        "161.9352364324168,\n",
        "174.56164027542448,\n",
        "161.62817356012405,\n",
        "167.65579546297906,\n",
        "170.88930983697742,\n",
        "147.22062198310996,\n",
        "151.85737964663497,\n",
        "158.03323614736198,\n",
        "135.77570282853696,\n",
        "161.25435141827515,\n",
        "193.33084953437478,\n",
        "155.43189514766172,\n",
        "155.89204074847055,\n",
        "179.23931091736836,\n",
        "146.485962651657,\n",
        "166.61617663518228,\n",
        "161.70927578953211,\n",
        "164.89798613982495,\n",
        "139.18195138901498,\n",
        "180.30341647946335,\n",
        "162.4811239647979,\n",
        "171.1035005376699,\n",
        "147.01137545913147,\n",
        "187.03282087175134,\n",
        "172.2476631392949,\n",
        "152.9814634955974,\n",
        "174.43159049461713,\n",
        "174.83877117002814,\n",
        "132.66857703218636,\n",
        "173.98029972846837,\n",
        "133.5435543737402,\n",
        "169.62941676289472,\n",
        "166.4887567852903,\n",
        "138.1150540623029,\n",
        "170.52532661450618]\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "altura = pd.Series(altura)\n",
        "\n",
        "type(altura)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld77Vb9mcRPQ"
      },
      "source": [
        "print(\"Promedio = \", altura.mean());print(\"Desviación Estándar=\",altura.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KETK1w6AcQsP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8Lb2tkLpks2"
      },
      "source": [
        "# Vamos a ajustarlo.\n",
        "import pandas as pd\n",
        "import scipy.stats as ss\n",
        "\n",
        "# df = pd.read_csv(\"alturas.csv\")\n",
        "\n",
        "media, desviacion = ss.norm.fit(altura)\n",
        "\n",
        "print(\"Promedio=\",media) # media = 160,37\n",
        "print(\"Desviación Estándar=\",desviacion) # desviacion = 17,41\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipGuCfkhrote"
      },
      "source": [
        "**En este caso nos informa de que estos datos parecen encajar con los de una distribución normal de media 160,37 y desviación típica 17,41.**\n",
        "\n",
        "¿Cómo de bueno es el ajuste? Kolmogorov\n",
        "\n",
        "Hemos hecho un ajuste, pero no sabemos qué tan bueno es. Existen varios métodos para poner a prueba los ajustes. Existen varios métodos, siendo los más populares Chi-Cuadrado y Kolmogorov-Smirnov.\n",
        "\n",
        "Chi-Cuadrado no se puede aplicar directamente sobre distribuciones continuas, aún así voy a explicar como se haría. Sin embargo, primero vamos a probar con Kolmogorov-Smirnov, que en SciPy es ktest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4FEmvhHr1fL"
      },
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as ss\n",
        "\n",
        "# df = pd.read_csv(\"altura.csv\")\n",
        "\n",
        "media, desviacion = ss.norm.fit(altura)\n",
        "\n",
        "d, pvalor = ss.kstest(altura,\"norm\",args=(media,desviacion)) # \"norm\" hace referencia al nombre en stats\n",
        "# o alternativamente\n",
        "d, pvalor = ss.kstest(altura,lambda x: ss.norm.cdf(x,media,desviacion))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAkjV4for1UF"
      },
      "source": [
        "pvalor\n",
        "# Si pvalor es mayor que 0.05 entonces el ajuste fue bondadoso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TLCpwFTCytB"
      },
      "source": [
        "# \"norm\" en el kstest() hace referencia al nombre de la cdf en stats\n",
        "from scipy import stats\n",
        "dir(stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faPsc07CDf3t"
      },
      "source": [
        "[Distribuciones estadísticas continuas en: **scipy.stats**](https://docs.scipy.org/doc/scipy/tutorial/stats/continuous.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ--mtlbEiae"
      },
      "source": [
        "# **LISTAR TODAS LAS DISTRIBUCIONES EN scipy.stats**\n",
        "\n",
        "[Ajuste y selección de distribuciones con Python](https://www.cienciadedatos.net/documentos/pystats01-ajuste-distribuciones-python.html)\n",
        "\n",
        "Además de diferenciar entre distribuciones continuas y discretas, es útil poder seleccionarlas por el rango de valores sobre el que está definida cada distribución (dominio). Por ejemplo, si se quiere modelar la velocidad del viento, aunque no se conozca el tipo exacto de distribución, se puede acotar a aquellas cuyo rango de valores está limitado entre  0  y  +inf .\n",
        "\n",
        "\n",
        "```\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "# Distribuciones agrupadas por dominio\n",
        "# ==============================================================================\n",
        "distribuciones = [getattr(stats,d) for d in dir(stats) \\\n",
        "                  if isinstance(getattr(stats,d), (stats.rv_continuous, stats.rv_discrete))]\n",
        "\n",
        "distribucion = []\n",
        "dominio_1 = []\n",
        "dominio_2 = []\n",
        "\n",
        "for dist in distribuciones:\n",
        "    distribucion.append(dist.name)\n",
        "    dominio_1.append(dist.a)\n",
        "    dominio_2.append(dist.b)\n",
        "\n",
        "info_distribuciones = pd.DataFrame({\n",
        "                        'distribucion': distribucion,\n",
        "                        'dominio_1': dominio_1,\n",
        "                        'dominio_2': dominio_2\n",
        "                      })\n",
        "\n",
        "info_distribuciones = info_distribuciones \\\n",
        "                      .sort_values(by=['dominio_1', 'dominio_2'])\\\n",
        "                      .reset_index(drop=True)\n",
        "\n",
        "print(\"-------------------------------------\")\n",
        "print(\"Información distribuciones scipy.stat\")\n",
        "print(\"-------------------------------------\")\n",
        "display(info_distribuciones)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KhIGKIvDduj"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Distribuciones agrupadas por dominio\n",
        "# ==============================================================================\n",
        "distribuciones = [getattr(stats,d) for d in dir(stats) \\\n",
        "                  if isinstance(getattr(stats,d), (stats.rv_continuous, stats.rv_discrete))]\n",
        "\n",
        "distribucion = []\n",
        "dominio_1 = []\n",
        "dominio_2 = []\n",
        "\n",
        "for dist in distribuciones:\n",
        "    distribucion.append(dist.name)\n",
        "    dominio_1.append(dist.a)\n",
        "    dominio_2.append(dist.b)\n",
        "\n",
        "info_distribuciones = pd.DataFrame({\n",
        "                        'distribucion': distribucion,\n",
        "                        'dominio_1': dominio_1,\n",
        "                        'dominio_2': dominio_2\n",
        "                      })\n",
        "\n",
        "info_distribuciones = info_distribuciones \\\n",
        "                      .sort_values(by=['dominio_1', 'dominio_2'])\\\n",
        "                      .reset_index(drop=True)\n",
        "\n",
        "print(\"-------------------------------------\")\n",
        "print(\"Información distribuciones scipy.stat\")\n",
        "print(\"-------------------------------------\")\n",
        "display(info_distribuciones)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in distribucion:\n",
        "    print(d)"
      ],
      "metadata": {
        "id": "ooXxJToCbUCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribucion[1:10]"
      ],
      "metadata": {
        "id": "ju9R3wzQb0pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T80m4W2Tr1KU"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('min_rows', 100)\n",
        "info_distribuciones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7FBj7VolrRd"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UN EJERCICIO CON LAS CASAS DE BOSTON\n",
        "\n",
        "# Describa el precio mediano de las casas de boston\n"
      ],
      "metadata": {
        "id": "lSGmb527sytb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wZadPSgr6y5"
      },
      "outputs": [],
      "source": [
        "# 1. Importar los módulos:\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. # Cargo las casas de boston y el precio promedio de las casas\n",
        "casas = pd.read_csv(\"/content/sample_data/california_housing_train.csv\")\n",
        "casas.median_house_value\n",
        "valores = casas.median_house_value\n",
        "valores.describe()"
      ],
      "metadata": {
        "id": "kQE608KbtFLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. # Muestro el histograma de densidad y su pdf; pdf = función de densidad de probabilidad\n",
        "import seaborn as sns\n",
        "sns.distplot(valores)"
      ],
      "metadata": {
        "id": "BUVIn23StLAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribucion"
      ],
      "metadata": {
        "id": "drwYzh0fahwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. # Realicemos un ajuste de la variable valores, para gamma. UTILIZANDO EL PARÁMETRO FIT DE displot()\n",
        "\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# UTILIZO displot() Y CON EL PARAMETRO fit, le paso la pdf teoríca a que quiero ajustar mis datos\n",
        "sns.distplot(valores, kde=False, fit=stats.gamma)"
      ],
      "metadata": {
        "id": "cQ8QDV8ZtRgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Realicemos el ajuste de valores para una normal\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# UTILIZO displot() Y CON EL PARAMETRO fit, le paso la pdf teoríca a que quiero ajustar mis datos\n",
        "sns.distplot(valores, kde=False, fit=stats.norm)"
      ],
      "metadata": {
        "id": "mKgDVpSstZip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats.f.fit(valores)"
      ],
      "metadata": {
        "id": "_g2Jpi35eaqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. # Hago la prueba de la bondad del ajuste para ver si el ajuste es bueno\n",
        "\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "media, desviacion = stats.norm.fit(valores)\n",
        "\n",
        "d, pvalor = stats.kstest(valores,\"norm\",args=(media,desviacion)) # \"norm\" hace referencia al nombre en stats\n",
        "# Perform the Kolmogorov-Smirnov test for goodness of fit.\n",
        "\n",
        "# This performs a test of the distribution F(x) of an observed\n",
        "# random variable against a given distribution G(x).\n",
        "\n",
        "pvalor"
      ],
      "metadata": {
        "id": "In5_7FLethkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "paramaetros = stats.gamma.fit(valores)\n",
        "\n",
        "stats.kstest(valores,\"gamma\",args=paramaetros)"
      ],
      "metadata": {
        "id": "8e2Ej5dMe0_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wml0IIox8wnd"
      },
      "source": [
        "# **EJERCICIOS SOBRE: \"Visualización y Ajuste de la distribución de un conjunto de datos\"**\n",
        "\n",
        "1.   Cargue el conjunto de datos acero. Visualice las variables: consumo y ProdTotal.\n",
        "2.   Cargue el conjunto de datos  agregados y visualice las variables: rcompa, rcompc y denscon.\n",
        "3.   Cargue el conjunto de datos embalajes y visualice las variables: ph, acidez, humedad\n",
        "\n",
        "---\n",
        "\n",
        "4. Para todos los puntos anteriores ajuste distribuciones de probabilidad para cada conjunto de datos.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h_BsCfcB3qw"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnLKwrdqB3Sq"
      },
      "source": [
        "# Cargo las casas de boston\n",
        "casas = pd.read_csv(\"/content/sample_data/california_housing_train.csv\")\n",
        "casas.median_house_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXEtlJkWZEDK"
      },
      "source": [
        "valores = casas.median_house_value\n",
        "valores.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t875y365Z1nA"
      },
      "source": [
        "# Muestro el histograma de densidad y su pdf\n",
        "# pdf = función de densidad de probabilidad\n",
        "import seaborn as sns\n",
        "sns.distplot(valores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuFdbQwzaIH1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwU7O_eoZgNC"
      },
      "source": [
        "# Realicemos el ajuste de valores\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# UTILIZO displot() Y CON EL PARAMETRO fit, le paso la pdf teoríca a que quiero ajustar mis datos\n",
        "sns.distplot(valores, kde=False, fit=stats.gamma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHidlc63ZD3p"
      },
      "source": [
        "# Realicemos el ajuste de valores para una normal\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# UTILIZO displot() Y CON EL PARAMETRO fit, le paso la pdf teoríca a que quiero ajustar mis datos\n",
        "sns.distplot(valores, kde=False, fit=stats.norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAMhe3ZUbhw-"
      },
      "source": [
        "# Hago la prueba para ver si el ajuste es bueno\n",
        "\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "paramatros = stats.norm.fit(valores)\n",
        "\n",
        "d, pvalor = stats.kstest(valores,\"norm\",args=paramatros) # \"norm\" hace referencia al nombre en stats\n",
        "# o alternativamente\n",
        "# d, pvalor = ss.kstest(altura,lambda x: ss.norm.cdf(x,media,desviacion))\n",
        "pvalor\n",
        "\n",
        "# La hipótesis nula es: valores es normal\n",
        "# Desición: si pvalor es menor que 0.05 entonces la afirmación anterior se rechaza\n",
        "if pvalor < 0.05:\n",
        "    print(pvalor, \" Es menor que 0.05 entonces no es normal\")\n",
        "elif pvalor > 0.05:\n",
        "    print(pvalor, \" Es mayor que 0.05 entonces SI es normal\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtbMW58JB2qB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tfqEqFboEBB"
      },
      "source": [
        "# **7. PARA AMPLIAR CONCEPTOS Y CODIGO**\n",
        "\n",
        "1.   [Ajuste y selección de distribuciones con Python](https://www.cienciadedatos.net/documentos/pystats01-ajuste-distribuciones-python.html)\n",
        "2.   [FITTER documentation](https://fitter.readthedocs.io/en/latest/). CREAR UN CUADERNO CON LA DOCUMENTACION DE fitter.\n",
        "3.   [Distribuciones de probabilidad con Python](https://relopezbriega.github.io/blog/2016/06/29/distribuciones-de-probabilidad-con-python/)\n",
        "4.   [Estadística en Python: ajustar datos a una distribución, parte VII](https://blog.adrianistan.eu/estadistica-python-ajustar-datos-una-distribucion-parte-vii)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z_j3qAlqRsy"
      },
      "source": [
        "#### **INTENTEMOS ALGO CON fitter**\n",
        "\n",
        "\n",
        "El paquete fitter proporciona una clase simple para identificar la distribución a partir de la cual se generan las muestras de datos. Utiliza 80 distribuciones de Scipy y le permite trazar los resultados para verificar cuál es la distribución más probable y los mejores parámetros.\n",
        "\n",
        "**Instalación:**\n",
        "\n",
        "```\n",
        "pip install fitter\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ6g_RMnpuDn"
      },
      "source": [
        "!pip install fitter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0mMp6Wko6Wc"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Primero, creemos muestras de datos con N = 10,000 puntos a partir de una distribución gamma:\n",
        "data = stats.gamma.rvs(2, loc=1.5, scale=2, size=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlzxbdyRo7R-"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu2mKxuzpBjG"
      },
      "source": [
        "Ahora, sin ningún conocimiento sobre la distribución o su parámetro, ¿cuál es la distribución que mejor se ajusta a los datos? Scipy tiene 80 distribuciones y la clase Fitter las escaneará todas, llamará a la función de ajuste por usted, ignorando aquellas que fallan o se ejecutan para siempre y finalmente le dará un resumen de las mejores distribuciones en el sentido de la suma de los errores cuadrados. Lo mejor es dar un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttLWYXgmpG2P"
      },
      "source": [
        "# fitter debe instalarce\n",
        "!pip install fitter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VPdd6l_o8k1"
      },
      "source": [
        "# Como se usa fitter\n",
        "\n",
        "from fitter import Fitter\n",
        "\n",
        "f = Fitter(data)\n",
        "\n",
        "f.fit()\n",
        "# may take some time since by default, all distributions are tried\n",
        "# but you call manually provide a smaller set of distributions\n",
        "f.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribucion"
      ],
      "metadata": {
        "id": "MYazrEplh9RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(valores,kde=False, fit=stats.gamma)"
      ],
      "metadata": {
        "id": "6W8eYmQEi43V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(valores,kde=False, fit=stats.f)"
      ],
      "metadata": {
        "id": "qOVMPm90ifhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp-4FsFO0S9i"
      },
      "source": [
        "from scipy import stats\n",
        "# data = stats.gamma.rvs(2, loc=1.5, scale=2, size=100000)\n",
        "\n",
        "from fitter import Fitter\n",
        "\n",
        "f = Fitter(data, distributions=['f','gamma', 'logistic','rayleigh', 'johnsonsb'])\n",
        "f.fit()\n",
        "f.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporto valores a un archivo de excel\n",
        "import pandas as pd\n",
        "\n",
        "valores.to_csv(\"valores.csv\")"
      ],
      "metadata": {
        "id": "wSmgsB5EjCs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kqY4JWLNxOuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3UFH73AOxOe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ic6Syl5CxPnh"
      }
    }
  ]
}